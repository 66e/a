### 让Matters上的作品，像星空闪烁 -- 历史文章引申关系的可视化
https://matters.news/@daz55/让matters上的作品-像星空闪烁-历史文章引申关系的可视化-zdpuAvAH9tqGLQL96o9eBcdqS6anpN8yhqrjeuejp24zvSN5Z

<details><summary>慎入🔞NSFW</summary>

Not Safe For Work
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Biohazard_Symbol_Specification.png/210px-Biohazard_Symbol_Specification.png">

<details><summary><b>风险自理Use At Your Own Risk🈲</summary>

### 互联网数字宣传z（二）：数字世界里的水军们如何介入现实世界里的z治
https://2newcenturynet.blogspot.com/2019/07/blog-post_93.html

互联网，包括但不限于社交媒体，带来的庞大信息量会如何对受众的心理和行为产生影响，尤其是在z治领域，这一直都是z治学、传播学、信息科学领域内的重要话题。

那些水军账号们的目的不仅仅是要操控选举，也可能是要干扰正常的公共交流、加剧sh割裂、影响sh运动，等等等等。

Samuel Woolley在2016年时就对此做过一个很好的综述，我也就不详细复述了。核心大意就是，z治参与者已经越来越多地采用自动化手段在互联网上传播特定内容，扭曲公共舆l和意见。
<img src="https://assets.matters.news/embed/04354d17-4cf6-4f48-9db7-f35b2593baa6/screen-shot-2019-06-23-at-4-06-20-pm.png">

不少的宣传行动（propaganda campaign）确实能够看出明显的受众对象。比如被讨论得最多的，俄罗s水军干预美国大选。而且，也不要以为恶意的z治水军不会出现于m主g家。在韩国，z治水军不止一次介入过总统大选，有的帮朴槿h，也有的帮文在y。

互联网政治水军并不是一个是一个非常有策略性且在不断进化的群体。它们擅长使用计算机程序来操控账号、喜欢使用hashtag，会制造出远远超过自身比例的内容（在英国脱欧的案例中，1%的账号制造了三分之一的内容）。
　　它们会传播特定媒体的新闻内容，会在低可信度的内容被创作的早期积极转发，通过各种手段吸引普通用户的注意。普通人自然无力抵抗这种被精心设计的圈套，很容易就会加入传播链，成为这个宣传病毒的感染者和传播源。`龖龖龖`

虚假错误信息，既不是水军内容的必需条件，也不是充分条件。很多半真半假、或者刻意误导的信息也有着极大的吸引力和伤害力；普通人也可能在信息的制造和传播中出错，产生有问题的内容。

有研究发现，在反疫苗的网络中舆论中也有大量的宣传战痕迹——参与者包括机器人账号、会传播恶意软件和商业信息的内容污染者、明确与俄罗sz府有关的真人水军（troll）。

机器人和内容污染者致力于扩散反疫苗的内容，俄罗s水军却是在两边用力，同时煽动意见不同的两方，加剧对立冲突。这种手法总结一下就是，先由机器人低成本地创造大量宣传原材料，然后再由真人水军介入同时向两方扩散，尝试制造反感，破坏对话。

这种同时加入双方论战、制造冲突的手法并不鲜见，最著名的案例就是BlackLiveMatters运动，俄罗s水军就装成了活动分子和两方论战者，左右互搏，积极制造冲突对立。（顺带一提，这种手法在简体z文舆论中很能见到，而且在关于zg的讨论和关于欧美z治的讨论中都有。

研究者认为
　　有恶意的境外势力
　　故意散播虚假错误信息来误导mz。而且，其中还有大比例的推特是来自于身分不明、但有恶意行为的激进用户在参与，这样一来，反疫苗的议题被人为制造出来了火热辩论的景象。这种宣传手法被称为astroturfing，这个词来自于astroturf（草皮），意思是利用伪装成普通草根层面的账号进行信息宣传，也可以就简单理解成"灌水

哪怕是明显的z治性水军（因为明确和俄罗sz府有关），也可以介入表面看起来非z治性的议题，进入深化sh矛盾情绪。另一个值得注意的是，有不少参与反疫苗争论的账号同时也在传播恶意软件或者商业信息。如果排除掉运营者在顺便挣点外快的可能，这倒是让我有点怀疑它们的身份其实并非z治性水军，而是商业性账号。背后的运营者在"洗粉"——通过某种特定内容的信息，聚集一大批特定类型和偏好的受众，就可以在未来进行定制的营销或者宣传。要向受众大量灌输某一立场的观点/推销特定种类的产品前，这种有目的性的宣传账号/营销账号都会先不断地发布受某群体喜欢的信息、发布某方激进观念，从而吸引更多的潜在受众并让受众群体变得越来越相似且容易信服。

不过，水军也不一定总是有效，这可能非常取决于它们在哪里活动，采取了什么方式。
　　甚至，z府里的g僚主义和低水平的动机也会造成宣传效果的大打折扣，这种例子就是zg水军，

机器人（bot）——由电脑程序控制的社交媒体账号——在灌水宣传中的使用。
　　辨别。最常用的做法是直接使用印第安纳大学的团队开发出来的检测工具BotorNot （现在叫Botometer

现在网络上的宣传账号，很多并不是100%的机器人，而是被真人和计算机程序混用的。

我个人以为，互联网上以虚假错误消息为主要内容的z治宣传带来的最大危害并非是误导了选m进而改变了选举，而是污染了有价值的信息、干扰了公共议事、扭曲了公共意见、让人们丧失对交流的信心和兴趣、进而造成了整个sh的各群体j层的割裂对立。`龖龖龖`
　　选举没有得到最好的结果，还可以通过其他手段补救、止损；然而，如果当q者不再能够通过s会舆l判断出mz的偏好变化，如果mz并不再愿意通过对话去介入公共生活，如果多数人都无法在数字世界里找到可靠的、有价值的信息，那我们将面临一个无法让人乐观的世界。这一点，对非m主制g家成立，对m主制g家也成立。

我们不应该将川普的上台、英国的脱欧归咎于社交媒体、网络水军或者俄罗s。我不否认他们会带来影响，但这背后其实还有更深刻的sh问题——为什么人们愿意相信并传播那些信息。水军们抓住了人性的弱点是肯定的，但这恐怕并不是可以那么简单回答的。虚假/错误信息的问题一直是存在的，这并不是数字时代独有的（当然，要说社交媒体加剧了这个问题，也站得住脚）。我们如今面临的问题是并非是"把社交媒体管起来""惩罚造谣者""打击俄罗s水军"就可以解决的，甚至这些方法很可能会适得其反。

</details>
</details>
