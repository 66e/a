<details><summary>慎入🔞NSFW</summary>

Not Safe For Work
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Biohazard_Symbol_Specification.png/210px-Biohazard_Symbol_Specification.png">

<details><summary><b>风险自理Use At Your Own Risk🈲</summary>

### 互联网数字宣传z：一场并不奢望我们能大胜的z争`龘龘龘`
https://2newcenturynet.blogspot.com/2019/08/blog-post_17.html

Molly Roberts 在她的书里提到了zgs查有一种方法叫做flooding（灌水）。大意就是在出现负面新闻时，用大量无关或者意义不大的信息灌水相关的讨论，来转移mz的讨论重点，以达到阻止敏感信息产生和传播的目的。我其实更倾向于把这种招数当作z治宣传，不过是一个相对被动和临时的宣传手段。

就当下的经验来看，水军的另一个目的还可能是制造sh的分裂和混乱。
　　水军的目的是增强传播、扩大分裂，那同时出现于左右两翼，刺激左右互搏，自然就是最好的选择了。既然能水军可以用转发来煽动对立，那再点情绪化的言辞或者假新闻，也就是不可避免的了。
　　对某些类型的政治宣传来说，分裂混战可能比一边倒要好，这是真的 Chaos is a ladder（"混乱是一个梯子"，语出《权力的游戏

机器人（bot）在z治宣传中的使用。有时候这个问题甚至会引申到人工智能和自动化力量对人类的影响上。这些都很值得重视，因为计算机程序和合适的社交媒体能够赋予使用者以空前强大的影响力。

但在我看来，我们在互联网上面临的威胁可能未必是机器人，或者自动化手段。真正可能要解决的问题是，【不想让被网络空间里充满被恶意操纵的信息，我们应该怎么办？

互联网上的各种z治宣传能够大行其道，除了社交媒体平台的设计对它们有利、容易形成意见一致的回音室(echo chamber)外，我个人以为人类的认知局限可能是一个很重要的原因。可能不少人都听说过确认性偏见/确认偏误（confirmation bias），也就是，哪怕同时看到正反两方意见，人们也更容易坚持自己以前所认为的，或者更容易轻信支持自己既有观念的证据。甚至，在遇到了相反意见后，人们甚至会固执己见，强化既有观念（这也就是所谓的backfire/逆火效应）。z治宣传就是利用了人类的薄弱处，才能够靠着虚假信息和情绪化内容不断激化矛盾，进而影响现实z治。一百年前，用着报纸、广播是这样；一百年后，用着Whatspp, 微信 还是这样。

个人以为还有个重要原因是，人们太在意别人的立场或者身份了，或者说倾向于去站队/给人贴标签。
　　在这种环境下，人们就太容易去产生in-group / out-group bias，也就是想你是不是和我一伙的——如果不是的话，【非我族类，其心必异】。再加上社交媒体本身赋予了每个人发言的机会，虽然别人未必看得到，但是我怀疑这种类似于endorsement（背书）的意见表达行为是很多人越来越固执己见、变得激进化的重要原因

关于这个问题，很多人说得比我好，推荐﻿@iyouport﻿的系列文章：信息分析心理学: 证据评估中常见的偏见(1)，信息分析心理学: 局部一致的骗局和不确定性证据(2)，信息分析心理学: 因果认知中的偏见(一)(3)，信息分析心理学: 因果认知中的偏见(二)(4) （原网站打不开了，只好用这些链接。更为详细的内容可以参考《情报分析心理学

审核机制或许是制止极端有害信息泛滥的最后防线，但在明显公认的不当或虚假信息和有冒犯倾向、让人不舒服的信息之间，有着极为宽广的灰色地带。让科技巨头们的普通审核员们掌握着信息筛选过滤的尺度，控制着人们在网络上所接触到的信息，这本身就是一件特别危险的事情。

如何确定惩罚的对象、尺度和标准，要赋予社交媒体多大的言论控制权力更是一个无法轻易解决的难题。更何况，（尤其是在非民主g家）q力机关更是乐意以保护sh此为借口，利用s查机制来按照它们的意图"净化"网络。

</details>
</details>
